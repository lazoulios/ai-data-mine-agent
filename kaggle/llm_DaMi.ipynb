{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# See information about the GPUs you are using\n# If you don't see GPUs, make sure you have enabled Kaggle's accelerators \n# Go to settings -> accelerator -> GPU T4x2\n!nvidia-smi\n\n# Download and install ollama to run within the Kaggle environment\n!curl -fsSL https://ollama.com/install.sh | sh\n\n# install necessary packages\n! pip install -qq pyngrok ollama\n\n# import Python dependencies\nimport subprocess\nfrom pyngrok import ngrok\nfrom kaggle_secrets import UserSecretsClient\nimport subprocess\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PARAMETERS\nNGROK_PORT = '11434'\n\n# auxiliary functions\ndef run(commands):\n    for command in commands:\n        with subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, \n                            stderr=subprocess.STDOUT, text=True, bufsize=1) as sp:\n            for line in sp.stdout:\n                if \"undefined reference\" in line:\n                    raise RuntimeError(\"Failed Processing.\")\n                print(line, end=\"\", flush=True)\n\ndef run(commands):\n    for command in commands:\n        with subprocess.Popen(command, shell = True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT, bufsize = 1) as sp:\n            for line in sp.stdout:\n                line = line.decode(\"utf-8\", errors = \"replace\")\n                if \"undefined reference\" in line:\n                    raise RuntimeError(\"Failed Processing.\")\n                print(line, flush = True, end = \"\")\n        pass\n    pass\npass\n\ndef start_ollama_server() -> None:\n    \"\"\"Starts the Ollama server.\"\"\"\n    # run([\"ollama serve\"])\n    subprocess.Popen(['ollama', 'serve'])\n    print(\"Ollama server started.\")\n\n\ndef check_ollama_port(port: str) -> None:\n    \"\"\"Check if Ollama server is running at the specified port.\"\"\"\n    try:\n        subprocess.run(['sudo', 'lsof', '-i', '-P', '-n'], check=True, capture_output=True, text=True)\n        if any(f\":{port} (LISTEN)\" in line for line in subprocess.run(['sudo', 'lsof', '-i', '-P', '-n'], capture_output=True, text=True).stdout.splitlines()):\n            print(f\"Ollama is listening on port {port}\")\n        else:\n            print(f\"Ollama does not appear to be listening on port {port}.\")\n    except subprocess.CalledProcessError as e:\n         print(f\"Error checking Ollama port: {e}\")\n\n\ndef setup_ngrok_tunnel(port: str, secret_manager: UserSecretsClient) -> ngrok.NgrokTunnel:\n    \"\"\"Sets up an ngrok tunnel.\n\n    Args:\n        port: The port to tunnel.\n\n    Returns:\n        The ngrok tunnel object.\n\n    Raises:\n        RuntimeError: If the ngrok authtoken is not set.\n    \"\"\"\n    ngrok_auth_token = secret_manager.get_secret(\"NGROK_AUTHTOKEN\")\n    if not ngrok_auth_token:\n        raise RuntimeError(\"NGROK_AUTHTOKEN is not set.\")\n\n    ngrok.set_auth_token(ngrok_auth_token)\n    tunnel = ngrok.connect(port, host_header=f'localhost:{port}')\n    print(f\"ngrok tunnel created: {tunnel.public_url}\")\n    return tunnel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start the ollama server and make sure it is running properly\nstart_ollama_server()\ncheck_ollama_port(NGROK_PORT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setup ngrok tunnel to be able to access the ollama server from the outside world\nuser_secrets = UserSecretsClient()\nngrok_tunnel = setup_ngrok_tunnel(NGROK_PORT, user_secrets)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(f'export OLLAMA_HOST={ngrok_tunnel.public_url}')\n\nmodel = \"gpt-oss\"\n\ncommands = [\n        f\"ollama pull {model}\",\n        f\"ollama run {model} \\\"create 10 sentences that ends with PAOK\\\"\"\n        # f\"curl {ngrok_tunnel.public_url}/api/chat -d '\\{\\\"model\\\": \\\"{model}\\\", \\\"stream\\\": false, \\\"messages\\\": [\\{ \\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"create 10 sentences that ends with apple\\\" }]}'\"\n]\nrun(commands)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}